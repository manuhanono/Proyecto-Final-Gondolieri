{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de LightGlue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'LightGlue' already exists and is not an empty directory.\n",
      "/Users/manu/Proyecto Final/Proyecto-Final-Gondolieri/LightGlue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manu/Library/Python/3.9/lib/python/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "## En teoria ya esta en el repo, pero por si acaso\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "if Path.cwd().name != \"LightGlue\":\n",
    "    !git clone --quiet https://github.com/cvg/LightGlue/\n",
    "    %cd LightGlue\n",
    "    !pip install --progress-bar off --quiet -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from LightGlue.lightglue import LightGlue, SuperPoint, DISK, SIFT, ALIKED, DoGHardNet\n",
    "from LightGlue.lightglue.utils import load_image, rbd\n",
    "from LightGlue.lightglue import viz2d\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import json\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defino parametros de configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino parámetros de configuración\n",
    "min_matches = 10  # Número mínimo de correspondencias necesarias para considerar que el objeto está presente\n",
    "margin = 50  # Margen en píxeles alrededor del área recortada\n",
    "max_keypoints = 2048  # Número máximo de puntos clave a extraer, puede no tener límite\n",
    "\n",
    "# Configurar el dispositivo y los modelos\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "extractor = SuperPoint(max_num_keypoints=max_keypoints).eval().to(device) #es donde se puede llamar a los modelos: DogHardNet, SuperPoint, SIFT, ALIKED, DISK\n",
    "matcher = LightGlue(features=\"superpoint\").eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizando el producto: TRESEMME SH LISO BOTOX ST P 12X500ML - 7791293050119.png\n",
      "Coincidencias en la mitad superior: 6, coincidencias en la mitad inferior: 12\n",
      "Objeto detectado con 12 correspondencias en la partición 0 para el producto: TRESEMME SH LISO BOTOX ST P 12X500ML - 7791293050119.png\n",
      "Falso positivo para el producto TRESEMME SH LISO BOTOX ST P 12X500ML - 7791293050119 en la partición 0. No se encontraron puntos dentro de las bounding boxes.\n",
      "Analizando el producto: TRESEMME AC DETOX CAPILAR ST P 12X500ML - 7791293050263.png\n",
      "Coincidencias en la mitad superior: 5, coincidencias en la mitad inferior: 9\n",
      "Falso negativo: Había una bounding box para el producto TRESEMME AC DETOX CAPILAR ST P 12X500ML - 7791293050263, pero no se encontraron suficientes puntos de coincidencia.\n",
      "Analizando el producto: TRESEMME SERUM BRILLO LAMELAR 12X170ML - 7891150094390.png\n",
      "Coincidencias en la mitad superior: 20, coincidencias en la mitad inferior: 4\n",
      "Objeto detectado con 20 correspondencias en la partición 0 para el producto: TRESEMME SERUM BRILLO LAMELAR 12X170ML - 7891150094390.png\n",
      "Producto TRESEMME SERUM BRILLO LAMELAR 12X170ML - 7891150094390 detectado correctamente en la partición 0 con 11 puntos dentro de las bounding boxes.\n",
      "Analizando el producto: TRESEMME SH ONDAS BOHO ST P 12X500ML - 7791293050195.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Procesar la mitad inferior\u001b[39;00m\n\u001b[1;32m     43\u001b[0m feats0_bottom \u001b[38;5;241m=\u001b[39m extractor\u001b[38;5;241m.\u001b[39mextract(product_image\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m---> 44\u001b[0m feats1_bottom \u001b[38;5;241m=\u001b[39m \u001b[43mextractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbottom_half\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m matches01_bottom \u001b[38;5;241m=\u001b[39m matcher({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage0\u001b[39m\u001b[38;5;124m\"\u001b[39m: feats0_bottom, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage1\u001b[39m\u001b[38;5;124m\"\u001b[39m: feats1_bottom})\n\u001b[1;32m     46\u001b[0m feats0_bottom, feats1_bottom, matches01_bottom \u001b[38;5;241m=\u001b[39m [rbd(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [feats0_bottom, feats1_bottom, matches01_bottom]]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Proyecto Final/Proyecto-Final-Gondolieri/LightGlue/lightglue/utils.py:144\u001b[0m, in \u001b[0;36mExtractor.extract\u001b[0;34m(self, img, **conf)\u001b[0m\n\u001b[1;32m    142\u001b[0m shape \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    143\u001b[0m img, scales \u001b[38;5;241m=\u001b[39m ImagePreprocessor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_conf, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconf})(img)\n\u001b[0;32m--> 144\u001b[0m feats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m feats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(shape)[\u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m.\u001b[39mto(img)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    146\u001b[0m feats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeypoints\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (feats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeypoints\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;241m/\u001b[39m scales[\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n",
      "File \u001b[0;32m~/Proyecto Final/Proyecto-Final-Gondolieri/LightGlue/lightglue/superpoint.py:160\u001b[0m, in \u001b[0;36mSuperPoint.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Shared Encoder\u001b[39;00m\n\u001b[1;32m    159\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1a(image))\n\u001b[0;32m--> 160\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1b\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    161\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x)\n\u001b[1;32m    162\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2a(x))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cargar la imagen de la góndola\n",
    "gondola_image_path = \"/Users/manu/Downloads/Mayo-Junio-Julio (teoricamente) 2/39-MJJ-.jpeg\"\n",
    "gondola_split = load_image(gondola_image_path)\n",
    "# Obtener dimensiones de la imagen\n",
    "height, width = gondola_split.shape[1:3]\n",
    "\n",
    "# Calcular las posiciones de recorte\n",
    "top_half_end = int(height * 0.6)  # 60% de la altura\n",
    "bottom_half_start = int(height * 0.4)  # 40% de la altura (20% de overlap)\n",
    "overlap = top_half_end - bottom_half_start  # Definir el solapamiento\n",
    "\n",
    "# Crear las mitades\n",
    "top_half = gondola_split[:, :top_half_end, :]\n",
    "bottom_half = gondola_split[:, bottom_half_start:, :]\n",
    "half_size = top_half_end  # Definir half_size como la altura de la mitad superior\n",
    "\n",
    "# Ruta a la carpeta de productos\n",
    "product_folder = Path(\"/Users/manu/Downloads/Cuidado Capilar/Tresseme\")\n",
    "\n",
    "TP, FP, TN, FN = 0, 0, 0, 0\n",
    "for product_image_path in product_folder.glob('*'):  \n",
    "    if product_image_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.avif', '.webp']: \n",
    "        print(f\"Analizando el producto: {product_image_path.name}\")\n",
    "\n",
    "        product_image = load_image(product_image_path)\n",
    "        \n",
    "        # Inicializar contadores para las mitades\n",
    "        top_half_matches = 0\n",
    "        bottom_half_matches = 0\n",
    "\n",
    "        # Procesar la mitad superior\n",
    "        feats0_top = extractor.extract(product_image.to(device))\n",
    "        feats1_top = extractor.extract(top_half.to(device))\n",
    "        matches01_top = matcher({\"image0\": feats0_top, \"image1\": feats1_top})\n",
    "        feats0_top, feats1_top, matches01_top = [rbd(x) for x in [feats0_top, feats1_top, matches01_top]]\n",
    "\n",
    "        kpts0_top, kpts1_top, matches_top = feats0_top[\"keypoints\"], feats1_top[\"keypoints\"], matches01_top[\"matches\"]\n",
    "        top_half_matches = len(matches_top)\n",
    "\n",
    "        # Procesar la mitad inferior\n",
    "        feats0_bottom = extractor.extract(product_image.to(device))\n",
    "        feats1_bottom = extractor.extract(bottom_half.to(device))\n",
    "        matches01_bottom = matcher({\"image0\": feats0_bottom, \"image1\": feats1_bottom})\n",
    "        feats0_bottom, feats1_bottom, matches01_bottom = [rbd(x) for x in [feats0_bottom, feats1_bottom, matches01_bottom]]\n",
    "\n",
    "        kpts0_bottom, kpts1_bottom, matches_bottom = feats0_bottom[\"keypoints\"], feats1_bottom[\"keypoints\"], matches01_bottom[\"matches\"]\n",
    "        bottom_half_matches = len(matches_bottom)\n",
    "\n",
    "        # Ajustar coordenadas para la mitad inferior\n",
    "        adjusted_kpts1_bottom = kpts1_bottom.detach().clone()  # Usar detach() y clone() para copiar\n",
    "        adjusted_kpts1_bottom[:, 1] += half_size - overlap  # Ajustar la coordenada y\n",
    "        print(f\"Coincidencias en la mitad superior: {top_half_matches}, coincidencias en la mitad inferior: {bottom_half_matches}\")\n",
    "        \n",
    "        # Elegir la mitad con más coincidencias\n",
    "        if top_half_matches >= bottom_half_matches:\n",
    "            matches = matches_top\n",
    "            m_kpts1 = kpts1_top[matches[..., 1]]\n",
    "        else:\n",
    "            matches = matches_bottom\n",
    "            m_kpts1 = adjusted_kpts1_bottom[matches[..., 1]]  # Usar las coordenadas ajustadas\n",
    "\n",
    "        if len(matches) >= min_matches:\n",
    "            print(f\"Objeto detectado con {len(matches)} correspondencias en la partición {idx} para el producto: {product_image_path.name}\")\n",
    "\n",
    "            # Cargar las bounding boxes del archivo JSON\n",
    "            gondola_image_path = Path(gondola_image_path)\n",
    "            json_path = gondola_image_path.stem + '.json'\n",
    "            with open(json_path, 'r') as f:\n",
    "                bounding_boxes_data = json.load(f)\n",
    "\n",
    "            # Verificar si el producto tiene una bounding box en el JSON\n",
    "            product_name = product_image_path.stem\n",
    "            bounding_box_found = False\n",
    "            total_in_bbox_count = 0  # Contador total de puntos dentro de cualquier bounding box\n",
    "            bboxes = []  # Lista para almacenar las bounding boxes\n",
    "\n",
    "            for region in bounding_boxes_data[\"regions\"]:\n",
    "                region_name = region[\"region_attributes\"][\"name\"]\n",
    "                \n",
    "                # Verificar si el nombre del producto coincide con el de la región\n",
    "                if product_name in region_name:\n",
    "                    # Obtener las coordenadas de la bounding box\n",
    "                    bbox = region[\"shape_attributes\"]\n",
    "                    x_min = bbox[\"x\"]\n",
    "                    y_min = bbox[\"y\"]\n",
    "                    x_max = x_min + bbox[\"width\"]\n",
    "                    y_max = y_min + bbox[\"height\"]\n",
    "                    bounding_box_found = True\n",
    "                    bboxes.append((x_min, y_min, x_max, y_max))  # Guardar bounding box\n",
    "\n",
    "                    # Verificar si la bounding box cae dentro de la partición\n",
    "                    if (x_max >= 0 and x_min <= gondola_split.shape[2] and\n",
    "                        y_max >= 0 and y_min <= gondola_split.shape[1]):\n",
    "                        \n",
    "                        # Contar cuántos puntos de coincidencia están dentro de la bounding box\n",
    "                        total_in_bbox_count += sum(\n",
    "                            1 for x, y in m_kpts1 if x_min <= x <= x_max and y_min <= y <= y_max\n",
    "                        )\n",
    "\n",
    "            # Visualización de puntos y bounding boxes con OpenCV\n",
    "            gondola_split_np = gondola_split.cpu().permute(1, 2, 0).numpy()  # Convertir a numpy\n",
    "            gondola_split_np = (gondola_split_np * 255).astype(np.uint8)  # Normalizar a [0, 255]\n",
    "            \n",
    "            # Dibujar bounding boxes\n",
    "            for bbox in bboxes:\n",
    "                if (bbox[2] <= gondola_split_np.shape[1] and bbox[0] >= 0 and\n",
    "                    bbox[3] <= gondola_split_np.shape[0] and bbox[1] >= 0):\n",
    "                    cv2.rectangle(gondola_split_np, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 0, 255), 2)  # Rojo\n",
    "\n",
    "            # Dibujar puntos encontrados\n",
    "            for x, y in m_kpts1:\n",
    "                cv2.circle(gondola_split_np, (int(x), int(y)), 5, (0, 255, 0), -1)  # Verde\n",
    "\n",
    "            # Mostrar la imagen\n",
    "            cv2.imshow(f'Puntos y Bounding Boxes para {product_name}', gondola_split_np)\n",
    "            cv2.waitKey(20)  # Esperar hasta que se presione una tecla\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "            # Si se encontraron bounding boxes\n",
    "            if bounding_box_found:\n",
    "                # Si la mayoría de los puntos están dentro de las bounding boxes\n",
    "                if total_in_bbox_count > 0:\n",
    "                    print(f\"Producto {product_name} detectado correctamente en la partición {idx} con {total_in_bbox_count} puntos dentro de las bounding boxes.\")\n",
    "                    TP += 1  # Verdadero positivo\n",
    "                else:\n",
    "                    print(f\"Falso positivo para el producto {product_name} en la partición {idx}. No se encontraron puntos dentro de las bounding boxes.\")\n",
    "                    FP += 1  # Falso positivo\n",
    "            else:\n",
    "                print(f\"Falso positivo: No se encontró bounding box para el producto {product_name}.\")\n",
    "\n",
    "        else:  # No hay suficientes coincidencias\n",
    "            # Cargar las bounding boxes del archivo JSON\n",
    "            gondola_image_path = Path(gondola_image_path)\n",
    "            json_path = gondola_image_path.stem + '.json'\n",
    "            with open(json_path, 'r') as f:\n",
    "                bounding_boxes_data = json.load(f)\n",
    "\n",
    "            # Verificar si el producto tiene una bounding box en el JSON\n",
    "            product_name = product_image_path.stem\n",
    "            bounding_box_found = any(product_name in region[\"region_attributes\"][\"name\"] for region in bounding_boxes_data[\"regions\"])\n",
    "\n",
    "            if bounding_box_found:\n",
    "                print(f\"Falso negativo: Había una bounding box para el producto {product_name}, pero no se encontraron suficientes puntos de coincidencia.\")\n",
    "                FN += 1  # Falso negativo\n",
    "            else:\n",
    "                print(f\"Verdadero negativo: No se encontró ni bounding box ni suficientes coincidencias para el producto {product_name}.\")\n",
    "                TN += 1  # Verdadero negativo\n",
    "\n",
    "    # Resultados finales\n",
    "print(f\"TP: {TP}, FP: {FP}, TN: {TN}, FN: {FN}\")\n",
    "\n",
    "        # Matriz de confusión\n",
    "print(\"Matriz de confusión:\")\n",
    "print(f\"              Predicted\")\n",
    "print(f\"           | Pos | Neg \")\n",
    "print(f\"  Actual   |-----|-----|\")\n",
    "print(f\"   Pos     | {TP}  | {FN} \")\n",
    "print(f\"   Neg     | {FP}  | {TN} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hola"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
