{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from LightGlue.lightglue import LightGlue, SuperPoint\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Definir imágenes y procesar cada producto en paralelo\u001b[39;00m\n\u001b[1;32m     48\u001b[0m gondola_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/manu/Downloads/Mayo-Junio-Julio (teoricamente) 2/39-MJJ-.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 49\u001b[0m gondola_split \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_prepare_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgondola_image_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m height, width \u001b[38;5;241m=\u001b[39m gondola_split\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m     51\u001b[0m top_half_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(height \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.6\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m, in \u001b[0;36mload_and_prepare_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_and_prepare_image\u001b[39m(image_path):\n\u001b[0;32m----> 2\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mload_image\u001b[49m(image_path)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_image' is not defined"
     ]
    }
   ],
   "source": [
    "def load_and_prepare_image(image_path):\n",
    "    image = load_image(image_path)\n",
    "    return image\n",
    "\n",
    "def calculate_matches(extractor, matcher, img0, img1):\n",
    "    feats0 = extractor.extract(img0.to(device))\n",
    "    feats1 = extractor.extract(img1.to(device))\n",
    "    matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n",
    "    return feats0, feats1, matches01\n",
    "\n",
    "def adjust_keypoints(kpts, half_size, overlap):\n",
    "    kpts_adjusted = kpts.detach().clone()\n",
    "    kpts_adjusted[:, 1] += half_size - overlap\n",
    "    return kpts_adjusted\n",
    "\n",
    "def draw_bounding_boxes(image, bboxes):\n",
    "    for bbox in bboxes:\n",
    "        if (bbox[2] <= image.shape[1] and bbox[0] >= 0 and\n",
    "            bbox[3] <= image.shape[0] and bbox[1] >= 0):\n",
    "            cv2.rectangle(image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 0, 255), 2)  # Rojo\n",
    "    return image\n",
    "\n",
    "def process_product_image(product_image_path, top_half, bottom_half, half_size, overlap, device):\n",
    "    print(f\"Analizando el producto: {product_image_path.name}\")\n",
    "    product_image = load_image(product_image_path)\n",
    "\n",
    "    top_half_matches, bottom_half_matches = 0, 0\n",
    "\n",
    "    feats0_top, feats1_top, matches01_top = calculate_matches(extractor, matcher, product_image, top_half)\n",
    "    kpts0_top, kpts1_top, matches_top = feats0_top[\"keypoints\"], feats1_top[\"keypoints\"], matches01_top[\"matches\"]\n",
    "    top_half_matches = len(matches_top)\n",
    "\n",
    "    feats0_bottom, feats1_bottom, matches01_bottom = calculate_matches(extractor, matcher, product_image, bottom_half)\n",
    "    kpts0_bottom, kpts1_bottom, matches_bottom = feats0_bottom[\"keypoints\"], feats1_bottom[\"keypoints\"], matches01_bottom[\"matches\"]\n",
    "    bottom_half_matches = len(matches_bottom)\n",
    "\n",
    "    adjusted_kpts1_bottom = adjust_keypoints(kpts1_bottom, half_size, overlap)\n",
    "\n",
    "    print(f\"Coincidencias en la mitad superior: {top_half_matches}, coincidencias en la mitad inferior: {bottom_half_matches}\")\n",
    "    return top_half_matches, bottom_half_matches\n",
    "\n",
    "# Definir parámetros y configurar el dispositivo y modelos\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "extractor = SuperPoint(max_num_keypoints=2048).eval().to(device)\n",
    "matcher = LightGlue(features=\"superpoint\").eval().to(device)\n",
    "\n",
    "# Definir imágenes y procesar cada producto en paralelo\n",
    "gondola_image_path = \"/Users/manu/Downloads/Mayo-Junio-Julio (teoricamente) 2/39-MJJ-.jpeg\"\n",
    "gondola_split = load_and_prepare_image(gondola_image_path)\n",
    "height, width = gondola_split.shape[1:3]\n",
    "top_half_end = int(height * 0.6)\n",
    "bottom_half_start = int(height * 0.4)\n",
    "top_half = gondola_split[:, :top_half_end, :]\n",
    "bottom_half = gondola_split[:, bottom_half_start:, :]\n",
    "half_size = top_half_end\n",
    "\n",
    "product_folder = Path(\"/Users/manu/Downloads/Cuidado Capilar/Tresseme\")\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    for product_image_path in product_folder.glob('*'):\n",
    "        if product_image_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.avif', '.webp']:\n",
    "            executor.submit(process_product_image, product_image_path, top_half, bottom_half, half_size, overlap, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
