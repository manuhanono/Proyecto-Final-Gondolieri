{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from LightGlue.lightglue import LightGlue, SuperPoint\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_image(image_path):\n",
    "    image = load_image(image_path)\n",
    "    return image\n",
    "\n",
    "def calculate_matches(extractor, matcher, img0, img1):\n",
    "    feats0 = extractor.extract(img0.to(device))\n",
    "    feats1 = extractor.extract(img1.to(device))\n",
    "    matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n",
    "    return feats0, feats1, matches01\n",
    "\n",
    "def adjust_keypoints(kpts, half_size, overlap):\n",
    "    kpts_adjusted = kpts.detach().clone()\n",
    "    kpts_adjusted[:, 1] += half_size - overlap\n",
    "    return kpts_adjusted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(json_path, 'r') as f:\n",
    "        bounding_boxes_data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Archivo JSON no encontrado: {json_path}\")\n",
    "    continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def process_product_image(product_image_path):\n",
    "    # Colocar aquí la lógica de procesamiento para cada imagen.\n",
    "    pass\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    for product_image_path in product_folder.glob('*'):\n",
    "        if product_image_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.avif', '.webp']:\n",
    "            executor.submit(process_product_image, product_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    feats0_top = extractor.extract(product_image.to(device))\n",
    "    feats1_top = extractor.extract(top_half.to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_image(image_path):\n",
    "    image = load_image(image_path)\n",
    "    return image\n",
    "\n",
    "def calculate_matches(extractor, matcher, img0, img1):\n",
    "    feats0 = extractor.extract(img0.to(device))\n",
    "    feats1 = extractor.extract(img1.to(device))\n",
    "    matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n",
    "    return feats0, feats1, matches01\n",
    "\n",
    "def adjust_keypoints(kpts, half_size, overlap):\n",
    "    kpts_adjusted = kpts.detach().clone()\n",
    "    kpts_adjusted[:, 1] += half_size - overlap\n",
    "    return kpts_adjusted\n",
    "\n",
    "def draw_bounding_boxes(image, bboxes):\n",
    "    for bbox in bboxes:\n",
    "        if (bbox[2] <= image.shape[1] and bbox[0] >= 0 and\n",
    "            bbox[3] <= image.shape[0] and bbox[1] >= 0):\n",
    "            cv2.rectangle(image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 0, 255), 2)  # Rojo\n",
    "    return image\n",
    "\n",
    "def process_product_image(product_image_path, top_half, bottom_half, half_size, overlap, device):\n",
    "    print(f\"Analizando el producto: {product_image_path.name}\")\n",
    "    product_image = load_image(product_image_path)\n",
    "\n",
    "    top_half_matches, bottom_half_matches = 0, 0\n",
    "\n",
    "    feats0_top, feats1_top, matches01_top = calculate_matches(extractor, matcher, product_image, top_half)\n",
    "    kpts0_top, kpts1_top, matches_top = feats0_top[\"keypoints\"], feats1_top[\"keypoints\"], matches01_top[\"matches\"]\n",
    "    top_half_matches = len(matches_top)\n",
    "\n",
    "    feats0_bottom, feats1_bottom, matches01_bottom = calculate_matches(extractor, matcher, product_image, bottom_half)\n",
    "    kpts0_bottom, kpts1_bottom, matches_bottom = feats0_bottom[\"keypoints\"], feats1_bottom[\"keypoints\"], matches01_bottom[\"matches\"]\n",
    "    bottom_half_matches = len(matches_bottom)\n",
    "\n",
    "    adjusted_kpts1_bottom = adjust_keypoints(kpts1_bottom, half_size, overlap)\n",
    "\n",
    "    print(f\"Coincidencias en la mitad superior: {top_half_matches}, coincidencias en la mitad inferior: {bottom_half_matches}\")\n",
    "    return top_half_matches, bottom_half_matches\n",
    "\n",
    "# Definir parámetros y configurar el dispositivo y modelos\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "extractor = SuperPoint(max_num_keypoints=2048).eval().to(device)\n",
    "matcher = LightGlue(features=\"superpoint\").eval().to(device)\n",
    "\n",
    "# Definir imágenes y procesar cada producto en paralelo\n",
    "gondola_image_path = \"/Users/manu/Downloads/Mayo-Junio-Julio (teoricamente) 2/39-MJJ-.jpeg\"\n",
    "gondola_split = load_and_prepare_image(gondola_image_path)\n",
    "height, width = gondola_split.shape[1:3]\n",
    "top_half_end = int(height * 0.6)\n",
    "bottom_half_start = int(height * 0.4)\n",
    "top_half = gondola_split[:, :top_half_end, :]\n",
    "bottom_half = gondola_split[:, bottom_half_start:, :]\n",
    "half_size = top_half_end\n",
    "\n",
    "product_folder = Path(\"/Users/manu/Downloads/Cuidado Capilar/Tresseme\")\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    for product_image_path in product_folder.glob('*'):\n",
    "        if product_image_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.avif', '.webp']:\n",
    "            executor.submit(process_product_image, product_image_path, top_half, bottom_half, half_size, overlap, device)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
